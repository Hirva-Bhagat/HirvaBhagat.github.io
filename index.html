<!doctype html>
<!--[if IE 7 ]>    <html lang="en-gb" class="isie ie7 oldie no-js"> <![endif]-->
<!--[if IE 8 ]>    <html lang="en-gb" class="isie ie8 oldie no-js"> <![endif]-->
<!--[if IE 9 ]>    <html lang="en-gb" class="isie ie9 no-js"> <![endif]-->
<!--[if (gt IE 9)|!(IE)]><!-->
<html lang="en-gb" class="no-js">
<!--<![endif]-->
<head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
    <!--[if lt IE 9]> 
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
    <![endif]-->
    <title>Hirva Bhagat</title>
    <meta name="description" content="">
    <!--[if lt IE 9]>
        <script src="http://html5shim.googlecode.com/svn/trunk/html5.js"></script>
    <![endif]-->
    <!--[if lte IE 8]>
		<script type="text/javascript" src="http://explorercanvas.googlecode.com/svn/trunk/excanvas.js"></script>
	<![endif]-->
    <link rel="stylesheet" href="css/bootstrap.min.css" />
    <link rel="stylesheet" type="text/css" href="css/isotope.css" media="screen" />
    <link rel="stylesheet" href="js/fancybox/jquery.fancybox.css" type="text/css" media="screen" />
    <link rel="stylesheet" type="text/css" href="css/da-slider.css" />
    <!-- Owl Carousel Assets -->
    <link href="js/owl-carousel/owl.carousel.css" rel="stylesheet">
    <link rel="stylesheet" href="css/styles.css" />
    <!-- Font Awesome -->
    <link href="font/css/font-awesome.min.css" rel="stylesheet">
</head>

<body>
    <header class="header">
        <div class="container">
            <nav class="navbar navbar-inverse" role="navigation">
                <div class="navbar-header">
                    <button type="button" id="nav-toggle" class="navbar-toggle" data-toggle="collapse" data-target="#main-nav">
                        <span class="sr-only">Toggle navigation</span>
                        <span class="icon-bar"></span>
                        <span class="icon-bar"></span>
                        <span class="icon-bar"></span>
                    </button>
                    <a href="#" class="navbar-brand scroll-top logo"><b> Hirva Bhagat</b></a>
                </div>
                <!--/.navbar-header-->
                <div id="main-nav" class="collapse navbar-collapse">
                    <ul class="nav navbar-nav" id="mainNav">
                        <li class="active"><a href="#home" class="scroll-link">Home</a></li>
                        <li><a href="#aboutUs" class="scroll-link">About Me</a></li>
                        <li><a href="#skills" class="scroll-link">Skills</a></li>
                        <li><a href="#experience" class="scroll-link">Experience</a></li>
                    </ul>
                </div>
                <!--/.navbar-collapse-->
            </nav>
            <!--/.navbar-->
        </div>
        <!--/.container-->
    </header>
    <!--/.header-->
    <div id="#top"></div>
    <section id="home">
        <div class="banner-container">
            <img src="images/banner-bg.jpg" alt="banner" />
            <div class="container banner-content">
                <div id="da-slider" class="da-slider">
                    <div class="da-slide">
                        <h2>Software Developer</h2>
                        <p>I develop software in JAVA and Python</p>
                        <div class="da-img"></div>
                    </div>
                    <div class="da-slide">
                        <h2>Machine Learning Engineer</h2>
                        <p>I devise automated machine learning solutions</p>
                        <div class="da-img"></div>
                    </div>
                    <div class="da-slide">
                        <h2>Mobile App Developer</h2>
                        <p>I build android apps using JAVA</p>
                        <div class="da-img"></div>
                    </div>
                    <div class="da-slide">
                        <h2>JavaScript/jQuery</h2>
                        <p>I know how to use JavaScript to make powerful data visualisations</p>
                        <div class="da-img"></div>
                    </div>
				<!--  <nav class="da-arrows">
                        <span class="da-arrows-prev"></span>
                        <span class="da-arrows-next"></span>
                    </nav> -->
                </div>
            </div>
        </div>
    </section>
    <section id="introText">
        <div class="container">
            <div class="text-center">
            <h1>I am a computer science student</h1>
              <p>Currently finishing my graduate degree of masters in computer science at virginia tech. I am an avid coder who loves to use logic to create solutions. I am also experienced in finding data solutions and using data to build machine learning models.</p>
            </div>
        </div>

    </section>
    <!--About-->
    <section id="aboutUs" class="secPad">
        <div class="container">
            <div class="heading text-center">
                <!-- Heading -->
                <h2>I am Hirva Bhagat, a Computer Science Engineer</h2>
                <p>I am well versed in multiple domains some of which are listed below. </p>
            </div>
            <div class="row">
                <!-- item -->
                <div class="col-md-4 text-center tileBox">
                   <div class="txtHead"> <i class="fa fa-desktop"></i>
                    <h3>ML <span class="id-color">Solutions</span></h3></div>
                    <p>I implement research based solutions, specifically designed to solve a particular problem statement using machine learning.</p>
                </div>
                <!-- end: -->

                <!-- item -->
                <div class="col-md-4 text-center tileBox">
                    <div class="txtHead"><i class="fa fa-css3"></i>
                    <h3>Data <span class="id-color">Visualisation</span></h3></div>
                    <p>It is important for data to be visualised in the best manner to gain necessary insights from it.</p>
                </div>
                <!-- end: -->

                <!-- item -->
                <div class="col-md-4 text-center tileBox">
                    <div class="txtHead"><i class="fa fa-lightbulb-o"></i>
                    <h3>Software <span class="id-color">Development</span></h3></div>
                    <p>Designing a system and building software for a particular feature or product is a skill that I have honed.</p>
                </div>
                <!-- end: -->
            </div>
        </div>
    </section>
    <!--Quote-->
    <section id="quote" class="bg-parlex">
        <div class="parlex-back">
            <div class="container secPad text-center">
				<h2>We’re here to put a dent in the universe. Otherwise why else even be here?</h2><h3>-Steve Jobs</h3>
            </div>
            <!--/.container-->
        </div>
    </section>
    
    <!--Skills-->
    <section id="skills" class="secPad white">
    	<div class="container">
        <div class="heading text-center">
                <!-- Heading -->
                <h2>My Skills</h2>
                <p>Below are listed the skills that I am most experienced in</p>
            </div>
        	<div class="row">
                <div class="col-sm-6">
                    <h2>Programming <strong>Skills</strong></h2>
                    <div class="row">
                        <div class="col-md-2 skilltitle">Python</div>
                        <div class="col-md-8">
                            <div class="progress">
                                <div class="progress-bar" role="progressbar" aria-valuenow="90" aria-valuemin="0" aria-valuemax="100" style="width: 90%;">
                                    <span class="sr-only">95% Complete</span>
                                </div>
                            </div>
                        </div>
                    </div>
                    <div class="row">
                        <div class="col-md-2 skilltitle">JAVA</div>
                        <div class="col-md-8">
                            <div class="progress">
                                <div class="progress-bar" role="progressbar" aria-valuenow="90" aria-valuemin="0" aria-valuemax="100" style="width: 90%;">
                                    <span class="sr-only">80% Complete</span>
                                </div>
                            </div>
                        </div>
                    </div>
                    <div class="row">
                        <div class="col-md-2 skilltitle">JavaScript</div>
                        <div class="col-md-8">
                            <div class="progress">
                                <div class="progress-bar" role="progressbar" aria-valuenow="80" aria-valuemin="0" aria-valuemax="100" style="width: 80%;">
                                    <span class="sr-only">80% Complete</span>
                                </div>
                            </div>
                        </div>
                    </div>
                    <div class="row">
                        <div class="col-md-2 skilltitle">D3</div>
                        <div class="col-md-8">
                            <div class="progress">
                                <div class="progress-bar" role="progressbar" aria-valuenow="90" aria-valuemin="0" aria-valuemax="100" style="width: 90%;">
                                    <span class="sr-only">80% Complete</span>
                                </div>
                            </div>
                        </div>
                    </div>      
                </div>
                <div class="col-sm-6">
                    <h2>Machine <strong>Learning</strong></h2>
                    <div class="row">
                        <div class="col-md-2 skilltitle">Pytorch</div>
                        <div class="col-md-8">
                            <div class="progress">
                                <div class="progress-bar" role="progressbar" aria-valuenow="90" aria-valuemin="0" aria-valuemax="100" style="width: 90%;">
                                    <span class="sr-only">90% Complete</span>
                                </div>
                            </div>
                        </div>
                    </div>
                    <div class="row">
                        <div class="col-md-2 skilltitle">Tensorflow</div>
                        <div class="col-md-8">
                            <div class="progress">
                                <div class="progress-bar" role="progressbar" aria-valuenow="80" aria-valuemin="0" aria-valuemax="100" style="width: 80%;">
                                    <span class="sr-only">80% Complete</span>
                                </div>
                            </div>
                        </div>
                    </div>
                    <div class="row">
                        <div class="col-md-2 skilltitle">Docker</div>
                        <div class="col-md-8">
                            <div class="progress">
                                <div class="progress-bar" role="progressbar" aria-valuenow="75" aria-valuemin="0" aria-valuemax="100" style="width: 75%;">
                                    <span class="sr-only">95% Complete</span>
                                </div>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
        </div>        
    </section>
    
    <!--Experience-->
    <section id="experience" class="secPad">
    	<div class="container">     
           <div class="heading text-center">
                <!-- Heading -->
                <h2>Experience</h2>
                  <p>I have worked mutiple internships and participated in a lot of hackathons that have contributed to my knowelege in this field</p>
            </div>
        <div id="timeline"><div class="row timeline-movement timeline-movement-top">
        <div class="timeline-badge timeline-future-movement">
            <a href="#">
                <span class="glyphicon glyphicon-plus"></span>
            </a>
        </div>
        <div class="timeline-badge timeline-filter-movement">
            <a href="#">
                <span class="glyphicon glyphicon-time"></span>
            </a>
        </div>
    
    </div>
    <div class="row timeline-movement">
    
        <div class="timeline-badge">
            <span class="timeline-balloon-date-day">June</span>
            <span class="timeline-balloon-date-month">2021</span>
        </div>
    
    
        <div class="col-sm-6  timeline-item">
            <div class="row">
                <div class="col-sm-11">
                    <div class="timeline-panel credits">
                        <ul class="timeline-panel-ul">
                            <li><span class="importo">Machine Learning Intern (TechTailored)</span></li>
                            <li><span class="causale">Collaborated on research related to land cover Satellite Image Analysis for Real Estate Growth
Prediction. Engineered a dataset of over 5000 images by the means of web scraping using selenium and augmentation which led to an increase of 11% in model accuracy. </span> </li>
                            <li><p><small class="text-muted"> Jan 2021 - May 2021</small></p> </li>
                        </ul>
                    </div>
    
                </div>
            </div>
        </div>
    
        <div class="col-sm-6  timeline-item">
            <div class="row">
                <div class="col-sm-offset-1 col-sm-11">
                    <div class="timeline-panel debits">
                        <ul class="timeline-panel-ul">
                            <li><span class="importo">Machine Learning Intern (Vectorlytics)</span></li>
                            <li><span class="causale">Participated in live projects related to leveraging Image Processing Techniques in Agriculture
and Crop Disease Identificationt. </span> </li>
                            <li><p><small class="text-muted"> Jan, 2020 - June, 2020</small></p> </li>
                        </ul>
                    </div>
    
                </div>
            </div>
        </div>
    </div>
    
    <!--due -->
    
    <div class="row timeline-movement">
    
    
        <div class="timeline-badge">
            <span class="timeline-balloon-date-day">Aug</span>
            <span class="timeline-balloon-date-month">2020</span>
        </div>
    
        <div class="col-sm-offset-6 col-sm-6  timeline-item">
            <div class="row">
                <div class="col-sm-offset-1 col-sm-11">
                    <div class="timeline-panel debits">
                        <ul class="timeline-panel-ul">
                            <li><span class="importo">KSV Purchase and Maintenanc</span></li>
                            <li><span class="causale">Launched an Android application developed to bridge gap in hierarchy between superiors and assigned
personnel in the university, where a user could submit complaints and all the information regarding
completion of the complaint, and timeline would be saved in database. </span> </li>
                            <li><p><small class="text-muted"> Jan, 2020 - June, 2020</small></p> </li>
                        </ul>
                    </div>
    
                </div>
            </div>
        </div>
    
        <div class="col-sm-6  timeline-item">
            <div class="row">
                <div class="col-sm-11">
                    <div class="timeline-panel credits">
                        <ul class="timeline-panel-ul">
                            <li><span class="importo">Automated System for Car Parking and Monitoring</span></li>
                            <li><span class="causale">Was awarded the Most Innovative Idea category at the Finale, beating 2000+ teams at
national level. </span> </li>
                            <li><p><small class="text-muted"> Sept 2019 - Nov, 2019</small></p> </li>
                        </ul>
                    </div>
    
                </div>
            </div>
        </div>
    
    
    </div>
    <div class="row timeline-movement">
    
    
        <div class="timeline-badge">
            <span class="timeline-balloon-date-day">Sept</span>
            <span class="timeline-balloon-date-month">2019</span>
        </div>
    
        <div class="col-sm-offset-6 col-sm-6  timeline-item">
            <div class="row">
                <div class="col-sm-offset-1 col-sm-11">
                    <div class="timeline-panel debits">
                        <ul class="timeline-panel-ul">
                            <li><span class="importo">Faculty Review Portal</span></li>
                            <li><span class="causale">Deployed in LDRP to take over 8400+ department reviews and generate an excel sheet
automatically. </span> </li>
                            <li><p><small class="text-muted"> Aug, 2018 - Aug, 2019</small></p> </li>
                        </ul>
                    </div>
    
                </div>
            </div>
        </div>
    
        <div class="col-sm-6  timeline-item">
            <div class="row">
                <div class="col-sm-11">
                    <div class="timeline-panel credits">
                        <ul class="timeline-panel-ul">
                            <li><span class="importo">Driving License Controlled Smart Vehicle</span></li>
                            <li><span class="causale">Programmed an authentication system for automobile controlled by driving license by an embedded
deep learned facial recognition model in a raspberry pi.. </span> </li>
                            <li><p><small class="text-muted"> Jan, 2018 - Oct, 2018</small></p> </li>
                        </ul>
                    </div>
    
                </div>
            </div>
        </div>
    
    
    </div>
    </div>
    </div>
    
    </section>


    <!--Portfolio-->
    <section id="portfolio" class="page-section section appear clearfix secPad">
        <div class="container">

            <div class="heading text-center">
                <!-- Heading -->
                <h2>Research</h2>
                <p>My research focus includes computer vision and driver safety</p>
            </div>

            <div class="row" style="background: whitesmoke; text-shadow: black">
                <nav id="filter" class="col-md-12 text-center">
                    <ul>
                        <li><span class="sub-heading"><h4>Literature Review: Driver Gaze Mapping</h4></span></li>
                            <div class="timeline-panel credits" style="background: whitesmoke; text-align: justify">
                                <ul class="timeline-panel-ul">

                                    <li><span class="importo">The human eye is the most interactive organ in their body. A person’s eye movements along with
the photometric characteristics provide vital information about them. They are also a source for
learning essential visual information. In computer vision, eye information is used in fields like
detection and recognition of face. In driver safety research, eye information is utilized in the
fields of computer vision for driver distraction detection, gauging driver attention and driver gaze
estimation. Driver gaze estimation relates to determining where the driver is looking. It helps us to
relate driver behavior and behavior of the road objects. The setting of driver gaze estimation uses
the face or front view of the driver to collect important information. This information is further
processed to get the R3 angle of where the driver is looking. Driver gaze estimation mainly relies
on two methodologies: Appearance based methods and model based methods.
                                    </span></li><li><span>
Model based methods use metric information like pupil location, iris and such to calculate or
learn the gaze angle. [1] Use estimated head pose and a head coordinate system along with pupil
location to determine gaze angle. They do eyeball center coordination for the gaze angle relationship
calculation. Their results are good with average error ranging below 10 degrees. Their methodology
is dependent on pupil tracking algorithm which needs better picture quality to detect the pupil.
Their proposed method is simple but it is not robust to low image quality and illumination changes.
The authors also do not account for occlusion since their method depends on the detect-ability of
the pupil. In general [1] represents the model based approach in the best capability. Since it is on
the earlier era of gaze estimation where complex architectures were not being used for this problem
statement, it is evident that a more robust approach to gaze estimation was needed.
                                    </span></li><li><span>
[2] was one of the firsts to use a full face appearance to regress gaze angle (2D and 3D). They use
a Spatial weights convolution neural network which learns specific regions. Some regions like the
back of the head are ignored whereas the eye region that contributes the most is emphasized. They
do an analysis on facial regions’ contribution to performance comparing two eyes and the proposed
full-face model. In conclusion they achieve overall accuracy improvement of 14.3% and 27.7% for
person-independent 3D gaze estimation on the benchmarks like MPIIGaze and EYEDIAP datasets.
For 2D gaze estimation, The centroid of the six face landmarks was used as the center of the face
and bounding box was estimated. The loss function minimized the distance between the ground
truth and estimation. MPIIGaze generic 3D face model was used to estimate the 3D headpose. For
the 3D model, the loss function is the distance between the predicted and ground-truth gaze angle.
They do achieve an improvement of 7.2% in 2D estimation and 14.3% on 3D estimation over the
baselines introduced. [2] is also more robust to facial appearance variation caused by extreme head
pose and gaze directions as well as illumination. Their method aims to help many problems that
use an appearance based methodology.
                                    </span></li><li><span>
Appearance-based methods work with eye/face images or image based features instead of using
dedicated devices. Appearance based methods would regress the images to an angle or classify a
gaze zone. These methods assume that the features when a driver is looking somehow maps to the
gaze positions. [3] Dgaze takes features like eye, face, head pose and face area in order to regress to
a 2D coordinate of where the driver is looking. They correlate the driver view with another view
plane where their gaze is fixated on. This makes it easier to correlate the front view and identify
the vehicles that the driver might be fixating on. Their ablation study to determine which features
give the highest accuracy leads to them choosing Left eye, face area and headpose. Their late fusion
neural network works well to integrate the information from all the features, beating benchmarks
like MPIIGAZE in terms of error rate(186.89 pixels). Dgaze distinguishes itself from other gaze
estimation methods by producing the gaze point on another plane/view which makes it very easy
to visualize what the driver is looking at.
                                    </span></li><li><span>
In a given road view there are many objects present that are not important to the driver. [4]
worked into incorporating the context of driver gaze in order to get better predictions. The local
and global context is concatenated with 4 fully connected layers along with the ego car’s future path
to determine the important road users. To resolve imbalance in their data, they use a weighted
approach in their model. Usually, neural networks perform better at finding relationships between
the data. In [4] case, using a path vector as a feature did not perform well. They also note that
their performance was affected by the distance between the ego vehicle and prediction. Overall,
they were successful in predicting important road users by context(F1 score 0.59) Rather than
appearance baseline(F1 score 0.53). The applications of [4] makes them stand out from other gaze
estimation methods. Since their importance is subjective and changes from driver to driver; A
context based system would learn a driver’s behavior in a better sense.
                                    </span></li><li><span>
Appearance based methods also involve methods that classify the gaze into labeled image zones
rather than regressing it to an angle. [5] is one of the methods that achieves a higher accuracy
in this task while also working on generalizing the methodology. Driver gaze zone estimation uses
features like driver face which can cause the model to learn driver specific information. Deep
learning models are notorious for finding and learning certain patterns that might backfire.[5]
makes their model more generalized by using just cropped images instead of a full face crop. This
is corroborated by their comparison study between using eye crop, face crop and face + context.
They also compare Alexnet and VGG in terms of architecture for gaze zone classification. VGG
with restricted context (eye crop) gives the best and comparable accuracy in terms with the driver
gaze zone methods (93%). Since, skin and other context information would still be learnt by the
model- there could be a pre-processing step to maybe improve the features. [5] showcased cross
driver study to examine generalization proves to be an important factor for any trained model.
Transformers are always used in state of the art NLP tasks. However, vision transformer
was introduced recently and have been achieving great results in many fields of computer vision.
With transformers being the new CNNs, they are also gaining traction in gaze estimation. Facial
appearance is affected by environmental factors and personal choices (sunglasses and other items of
occlusion). Here, transformers can help my incorporating global information. [6] Uses the popular
ViT architecture for gaze estimation. Since image patching or using a pure transformer architecture
could be contradictory to capturing detailed context, hybrid architecture is also popular. Using
CNN for preprocessing and then using transformer architecture to capture global context. [6] uses
both pure and hybrid approaches. For the hybrid approach, classic ResNet architecture is used.
It is a known fact that vision transformers in general need a lot of data to perform well. Usually,
pre training is applied to achieve a good accuracy. Here, hybrid transformer outperforms state
of the art methods in gaze estimation with pre-training. Ablation study for self attention and
deep convolution study is very interesting. Self attention which is generally used in a transformer
architecture increases the performance when applied to hybrid in [6]. However, deep convolution
which improves CNN performance degrades the performance of the proposed network. It is clear
that transformers when integrated with CNNs are better at capturing the information as they learn
both local and global features.
                                    </span></li><li><span>
Overall we can see a trend in this review that the gaze estimation methods go from a geometric
model based approach to zone classification/angle estimation with deep learning and ultimately
transformers. With all of the new methods coming into place that significantly improves on the
previous works. It is evident that the gaze estimation research is ever growing and there is still a
lot of need for robust models but moreover, there is a need for models that use the gaze estimation
tasks for driver safety issues. Combining gaze estimation with driver road view and correlating
both events will give us information to help with driver and ego vehicle tasks.
                                    </span></li><li><span class="sub-heading"><h4>
References</h4>
                                    </span></li><li><span>
[1] Li Jianfeng and Li Shigang. Eye-model-based gaze estimation by rgb-d camera. In 2014 IEEE
Conference on Computer Vision and Pattern Recognition Workshops, pages 606–610, 2014.
                                    </span></li><li><span>
[2] Xucong Zhang, Yusuke Sugano, Mario Fritz, and Andreas Bulling. It’s written all over your
face: Full-face appearance-based gaze estimation. In Proceedings of the IEEE Conference on
Computer Vision and Pattern Recognition Workshops, pages 51–60, 2017.
                                    </span></li><li><span>
[3] Isha Dua, Thrupthi Ann John, Riya Gupta, and C.V. Jawahar. Dgaze: Driver gaze mapping on
road. In 2020 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS),
pages 5946–5953, 2020.
                                    </span></li><li><span>
[4] Alireza Rahimpour, Sujitha Martin, Ashish Tawari, and Hairong Qi. Context aware road-
user importance estimation (icare). In 2019 IEEE Intelligent Vehicles Symposium (IV), pages
2337–2343, 2019.
                                    </span></li><li><span>
[5] Sourabh Vora, Akshay Rangesh, and Mohan M. Trivedi. On generalizing driver gaze zone
estimation using convolutional neural networks. In 2017 IEEE Intelligent Vehicles Symposium
(IV), pages 849–854, 2017.
                                    </span></li><li><span>
[6] Yihua Cheng and Feng Lu. Gaze estimation using transformer. CoRR, abs/2105.14424, 2021.</span></li>
                                </ul>
                            </div>

                    </ul>
                </nav>
            </div>

        </div>
    </section>

    <a href="#top" class="topHome"><i class="fa fa-chevron-up fa-2x"></i></a>

    <!--[if lte IE 8]><script src="//ajax.googleapis.com/ajax/libs/jquery/1.11.0/jquery.min.js"></script><![endif]-->
    <script src="js/modernizr-latest.js"></script>
    <script src="js/jquery-1.8.2.min.js" type="text/javascript"></script>
    <script src="js/bootstrap.min.js" type="text/javascript"></script>
    <script src="js/jquery.isotope.min.js" type="text/javascript"></script>
    <script src="js/fancybox/jquery.fancybox.pack.js" type="text/javascript"></script>
    <script src="js/jquery.nav.js" type="text/javascript"></script>
    <script src="js/jquery.cslider.js" type="text/javascript"></script>
    <script src="js/custom.js" type="text/javascript"></script>
    <script src="js/owl-carousel/owl.carousel.js"></script>
</body>
</html>
